# tabbyUI

A modern chat interface for tabbyAPI that provides an intuitive way to interact with large language models.

## Features

- Clean, intuitive chat interface
- Support for multiple message types including text and images
- Model management with customizable parameters
- Specialized model selection for different tasks:
  - General Assistant
  - Vision tasks
  - Coding assistance
  - Chain-of-thought reasoning
- Draft model support for faster generation
- Progress monitoring during model loading
- Conversation organization with folders
- Settings management for API configuration
- Model parameter persistence
- Regeneration capability

## Getting Started

1. Ensure you have a running [tabbyAPI](https://github.com/theroyallab/tabbyAPI) instance
2. Configure your server URL and API keys in the settings
3. Load your preferred model through the model management interface
4. Start chatting!

## Development

This project is built with:
- React + TypeScript
- Material-UI components
- Vite build system

To run locally:
```bash
npm install
npm run dev
```

## Contributing

Contributions are welcome! Please feel free to submit issues and pull requests.
